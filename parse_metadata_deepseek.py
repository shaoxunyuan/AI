#!/usr/bin/env python3
import os
import sys
import requests
import pandas as pd
import subprocess
import json
import re
from io import StringIO

# ========== é…ç½®ä¿¡æ¯ ==========
API_KEY = os.getenv("DEEPSEEK_API_KEY")
API_URL = "https://api.deepseek.com/v1/chat/completions"

if not API_KEY:
    print("âŒ è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼šexport DEEPSEEK_API_KEY='ä½ çš„key'")
    sys.exit(1)


# ========== DeepSeek API è°ƒç”¨å‡½æ•° ==========
def ask_deepseek(prompt):
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
    }
    data = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system",
             "content": "ä½ æ˜¯ä¸€åèµ„æ·±ç”Ÿç‰©ä¿¡æ¯ä¸“å®¶ï¼Œæ“…é•¿è§£æ SRA metadata(pysradb) å¹¶æå–æ ·æœ¬åˆ†ç»„é€»è¾‘ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2,
    }

    try:
        resp = requests.post(API_URL, headers=headers, json=data, timeout=120)
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"âŒ DeepSeek API è¯·æ±‚å¤±è´¥: {e}")
        sys.exit(1)


# ========== ä½¿ç”¨pysradbè·å–metadata ==========
def get_metadata_with_pysradb(prj_id):
    """
    ä½¿ç”¨pysradbå‘½ä»¤è¡Œå·¥å…·è·å–metadata
    """
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ {prj_id} çš„metadata...")
    
    try:
        # æ‰§è¡Œpysradbå‘½ä»¤
        cmd = ["pysradb", "metadata", prj_id, "--expand"]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        
        if result.returncode != 0:
            print(f"âŒ pysradbå‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}")
            return None
            
        # è§£æè¾“å‡ºçš„TSVæ•°æ®
        metadata_df = pd.read_csv(StringIO(result.stdout), sep="\t", dtype=str)
        print(f"âœ… æˆåŠŸè·å– {len(metadata_df)} æ¡æ ·æœ¬è®°å½•")
        return metadata_df
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ pysradbå‘½ä»¤æ‰§è¡Œé”™è¯¯: {e}")
        print(f"stderr: {e.stderr}")
        return None
    except Exception as e:
        print(f"âŒ è§£æmetadataæ—¶å‡ºé”™: {e}")
        return None


# ========== æ‰¹é‡è§„åˆ™åº”ç”¨å‡½æ•° ==========
def apply_grouping_rules(sample_df, rules_dict):
    """
    æ ¹æ®è§„åˆ™å­—å…¸æ‰¹é‡åº”ç”¨åˆ†ç»„é€»è¾‘
    rules_dict: {åˆ—å: è§„åˆ™å­—å…¸}
    è§„åˆ™å­—å…¸æ ¼å¼: {å­—æ®µå€¼: åˆ†ç»„åç§°}
    """
    sample_df = sample_df.copy()
    
    # ä¸ºæ¯ä¸ªè§„åˆ™åˆ—åˆ›å»ºåˆ†ç»„åˆ—
    for col_name, rules in rules_dict.items():
        if col_name not in sample_df.columns:
            print(f"âš ï¸  è­¦å‘Š: åˆ— '{col_name}' ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯¥è§„åˆ™")
            continue
            
        group_col_name = f"group_{col_name}"
        sample_df[group_col_name] = "NA"  # é»˜è®¤å€¼
        
        # åº”ç”¨è§„åˆ™
        for value_pattern, group_name in rules.items():
            # å¤„ç†æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            if value_pattern.startswith("regex:"):
                pattern = value_pattern[6:]
                mask = sample_df[col_name].str.contains(pattern, case=False, na=False)
                sample_df.loc[mask, group_col_name] = group_name
            # å¤„ç†ç²¾ç¡®åŒ¹é…
            else:
                mask = sample_df[col_name] == value_pattern
                sample_df.loc[mask, group_col_name] = group_name
    
    return sample_df


# ========== ä¸»æµç¨‹ ==========
def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python parse_metadata_to_excel.py PRJNAxxxxxx")
        print("ç¤ºä¾‹: python parse_metadata_to_excel.py PRJNA123456")
        sys.exit(1)

    prj_id = sys.argv[1]
    output_file = f"{prj_id}_metadata.xlsx"

    # æ£€æŸ¥pysradbæ˜¯å¦å¯ç”¨
    try:
        subprocess.run(["pysradb", "--version"], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ æœªæ‰¾åˆ°pysradbï¼Œè¯·å…ˆå®‰è£…: pip install pysradb")
        sys.exit(1)

    # Step 1ï¸âƒ£ ä½¿ç”¨pysradbè·å–metadata
    df = get_metadata_with_pysradb(prj_id)
    if df is None:
        print("âŒ æ— æ³•è·å–metadataï¼Œè¯·æ£€æŸ¥PRJNA IDæ˜¯å¦æ­£ç¡®")
        sys.exit(1)
        
    original_df = df.copy()  # ä¿å­˜åŸå§‹æ•°æ®
    df = df.fillna("NA")

    print(f"âœ… å·²è¯»å– metadataï¼š{len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
    print("ğŸ“Š åˆ—ä¿¡æ¯:")
    for col in df.columns:
        unique_count = df[col].nunique()
        print(f"   - {col}: {unique_count} ä¸ªå”¯ä¸€å€¼")
        if unique_count <= 10 and unique_count > 1:  # åªæ˜¾ç¤ºè¾ƒå°‘å”¯ä¸€å€¼çš„å…·ä½“å†…å®¹
            print(f"     å”¯ä¸€å€¼: {list(df[col].unique())}")

    # Step 2ï¸âƒ£ è‡ªåŠ¨åˆ¤æ–­ study-level ä¸ sample-level åˆ—
    study_cols = []
    sample_cols = []
    for col in df.columns:
        if df[col].nunique() == 1:
            study_cols.append(col)
        else:
            sample_cols.append(col)

    study_df = pd.DataFrame({
        "å­—æ®µå": study_cols,
        "å­—æ®µå€¼": [df[col].iloc[0] for col in study_cols]
    })
    sample_df = df[sample_cols].copy()

    print(f"\nğŸ§© Study å±‚å­—æ®µ: {len(study_cols)} ä¸ª")
    print(f"ğŸ§¬ Sample å±‚å­—æ®µ: {len(sample_cols)} ä¸ª")

    # Step 3ï¸âƒ£ æ„é€  AI æç¤ºè¯ - åªè®©AIç†è§£é€»è¾‘ï¼Œä¸ç”Ÿæˆä»£ç 
    preview_data = []
    for col in sample_cols:
        unique_vals = sample_df[col].unique()[:10]  # æ¯åˆ—æœ€å¤šæ˜¾ç¤º10ä¸ªå”¯ä¸€å€¼
        preview_data.append({
            "åˆ—å": col,
            "å”¯ä¸€å€¼æ•°é‡": sample_df[col].nunique(),
            "ç¤ºä¾‹å€¼": list(unique_vals)
        })
    
    preview_df = pd.DataFrame(preview_data)
    
    prompt = f"""
ä½œä¸ºç”Ÿç‰©ä¿¡æ¯ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹SRA metadataæ ·æœ¬æ•°æ®çš„åˆ†ç»„é€»è¾‘ï¼š

æ•°æ®é›†åˆ—ä¿¡æ¯ï¼š
{preview_df.to_string(index=False)}

è¯·åŸºäºè¿™äº›åˆ—çš„æ•°æ®æ¨¡å¼ï¼Œè¯†åˆ«å‡ºå¯èƒ½çš„åˆ†ç»„é€»è¾‘ã€‚é‡ç‚¹å…³æ³¨ï¼š
1. å“ªäº›åˆ—åŒ…å«æ˜æ˜¾çš„åˆ†ç»„ä¿¡æ¯ï¼ˆå¦‚AS_patient, Healthyç­‰ï¼‰
2. è¿™äº›åˆ—ä¸­çš„å€¼å¦‚ä½•å¯¹åº”åˆ°ä¸åŒçš„å®éªŒç»„

å½“å‰æ•°æ®ä¸­å…³é”®åˆ—çš„æ‰€æœ‰å”¯ä¸€å€¼ï¼š
experiment_titleåˆ—æ‰€æœ‰å€¼ï¼š{list(sample_df['experiment_title'].unique())}

è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼Œåªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–è¯´æ˜ï¼š
{{
    "grouping_columns": [
        {{
            "column_name": "åˆ—å",
            "grouping_logic": {{
                "å­—æ®µå€¼æˆ–æ¨¡å¼1": "åˆ†ç»„åç§°1",
                "å­—æ®µå€¼æˆ–æ¨¡å¼2": "åˆ†ç»„åç§°2"
            }},
            "confidence": "é«˜/ä¸­/ä½",
            "reason": "åˆ†ç»„é€»è¾‘è¯´æ˜"
        }}
    ]
}}

é‡è¦è¦æ±‚ï¼š
- å¯¹äºæ–‡æœ¬æ¨¡å¼åŒ¹é…ï¼Œä½¿ç”¨ "regex:æ¨¡å¼" ä½œä¸ºé”®
- åˆ†ç»„åç§°è¦ç®€æ´æ˜ç¡®ï¼ˆå¦‚"AS", "Control"ï¼‰
- åªè¾“å‡ºæœ€æœ‰æŠŠæ¡çš„åˆ†ç»„è§„åˆ™
- å¿…é¡»ç¡®ä¿åˆ†ç»„è§„åˆ™èƒ½å¤Ÿè¦†ç›–æ•°æ®ä¸­æ‰€æœ‰å‡ºç°çš„æ¨¡å¼ï¼Œä¸èƒ½æœ‰é—æ¼
- ä»”ç»†åˆ†æexperiment_titleåˆ—çš„æ‰€æœ‰å”¯ä¸€å€¼ï¼Œç¡®ä¿æ¯ä¸ªå€¼éƒ½èƒ½åŒ¹é…åˆ°æŸä¸ªè§„åˆ™
- å¦‚æœå‘ç°æ•°æ®ä¸­æœ‰å¤šç§æ˜æ˜¾ä¸åŒçš„æ¨¡å¼ï¼Œéƒ½åº”è¯¥åŒ…å«åœ¨åˆ†ç»„é€»è¾‘ä¸­
- è¯·ç¡®ä¿åˆ†ç»„è§„åˆ™çš„é¡ºåºæ˜¯ä»ä¸€èˆ¬åˆ°ç‰¹æ®Šï¼Œå³æ›´ä¸€èˆ¬çš„è§„åˆ™ï¼ˆåŒ¹é…èŒƒå›´å¤§ï¼‰åœ¨å‰ï¼Œæ›´ç‰¹æ®Šçš„è§„åˆ™ï¼ˆåŒ¹é…èŒƒå›´å°ï¼‰åœ¨åã€‚ä¾‹å¦‚ï¼Œå…ˆåŒ¹é…â€œ.*disease.*â€ï¼Œå†åŒ¹é…â€œ.*severe disease.*â€
"""

    print("ğŸ¤– æ­£åœ¨è®© DeepSeek åˆ†ææ ·æœ¬åˆ†ç»„é€»è¾‘...")
    analysis_result = ask_deepseek(prompt)
    print("\n=== DeepSeek åˆ†æç»“æœ ===\n")
    print(analysis_result)
    print("========================\n")

    # Step 4ï¸âƒ£ è§£æAIè¿”å›çš„åˆ†ç»„è§„åˆ™å¹¶åº”ç”¨
    grouping_rules_applied = False
    rules_json = None
    try:
        # æå–JSONéƒ¨åˆ†ï¼ˆå¤„ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜ï¼‰
        json_match = re.search(r'\{.*\}', analysis_result, re.DOTALL)
        if json_match:
            rules_json = json.loads(json_match.group())
            
            rules_dict = {}
            for col_info in rules_json.get("grouping_columns", []):
                col_name = col_info["column_name"]
                grouping_logic = col_info["grouping_logic"]
                confidence = col_info["confidence"]
                reason = col_info["reason"]
                
                print(f"ğŸ“‹ åº”ç”¨åˆ†ç»„è§„åˆ™ - åˆ—: {col_name}")
                print(f"   ç½®ä¿¡åº¦: {confidence}")
                print(f"   ç†ç”±: {reason}")
                print(f"   è§„åˆ™: {grouping_logic}")
                
                rules_dict[col_name] = grouping_logic
            
            # åº”ç”¨åˆ†ç»„è§„åˆ™
            if rules_dict:
                sample_df = apply_grouping_rules(sample_df, rules_dict)
                grouping_rules_applied = True
                print("âœ… åˆ†ç»„è§„åˆ™åº”ç”¨å®Œæˆ")
            else:
                print("âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†ç»„è§„åˆ™")
            
        else:
            print("âŒ æ— æ³•è§£æDeepSeekè¿”å›çš„åˆ†ç»„è§„åˆ™")
            
    except Exception as e:
        print(f"âŒ è§£æåˆ†ç»„è§„åˆ™æ—¶å‡ºé”™: {e}")
        print("âš ï¸  å°†ç»§ç»­è¾“å‡ºæœªåˆ†ç»„çš„metadata")

    # Step 5ï¸âƒ£ è¾“å‡º Excel æ–‡ä»¶ï¼ˆåŒ…å«ä¸‰ä¸ªsheetï¼‰
    with pd.ExcelWriter(output_file, engine="openpyxl") as writer:
        # Sheet 1: åŸå§‹metadata
        original_df.to_excel(writer, sheet_name="metadata", index=False)
        
        # Sheet 2: studyå±‚é¢ä¿¡æ¯
        study_df.to_excel(writer, sheet_name="study", index=False)
        
        # Sheet 3: sampleå±‚é¢ä¿¡æ¯ï¼ˆåŒ…å«åˆ†ç»„ç»“æœï¼‰
        sample_df.to_excel(writer, sheet_name="sample", index=False)
        
        # å¯é€‰ï¼šæ·»åŠ ä¸€ä¸ªåˆ†ç»„è§„åˆ™è¯´æ˜çš„sheet
        if grouping_rules_applied and rules_json:
            rules_summary = []
            for col_info in rules_json.get("grouping_columns", []):
                rules_summary.append({
                    "è§„åˆ™åˆ—": col_info["column_name"],
                    "åˆ†ç»„é€»è¾‘": str(col_info["grouping_logic"]),
                    "ç½®ä¿¡åº¦": col_info["confidence"],
                    "è¯´æ˜": col_info["reason"]
                })
            rules_df = pd.DataFrame(rules_summary)
            rules_df.to_excel(writer, sheet_name="grouping_rules", index=False)

    print(f"\nâœ… å·²ç”Ÿæˆ Excel æ–‡ä»¶ï¼š{output_file}")
    print("ğŸ“‘ åŒ…å«ä»¥ä¸‹å·¥ä½œè¡¨:")
    print(f"   - metadata: {len(original_df)} è¡ŒåŸå§‹æ•°æ®")
    print(f"   - study: {len(study_df)} æ¡é¡¹ç›®å­—æ®µ")
    print(f"   - sample: {len(sample_df)} æ¡æ ·æœ¬è®°å½•")
    if grouping_rules_applied:
        print(f"   - grouping_rules: åˆ†ç»„è§„åˆ™è¯´æ˜")
    
    # æ˜¾ç¤ºåˆ†ç»„ç»“æœç»Ÿè®¡
    if grouping_rules_applied:
        group_cols = [col for col in sample_df.columns if col.startswith('group_')]
        if group_cols:
            print("\nğŸ“ˆ åˆ†ç»„ç»“æœç»Ÿè®¡:")
            for col in group_cols:
                print(f"   {col}:")
                group_counts = sample_df[col].value_counts()
                for group, count in group_counts.items():
                    print(f"     - {group}: {count} ä¸ªæ ·æœ¬")


if __name__ == "__main__":
    main()